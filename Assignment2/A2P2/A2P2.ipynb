{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxopt\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "import math\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadInput(c1,c2):\n",
    "    df = pd.read_csv('./fashion_mnist/train.csv',header=None)\n",
    "    data = df.to_numpy()\n",
    "    index = np.logical_or(data[:,784]==c1 ,data[:,784]==c2)\n",
    "    X_train = data[index][:,:-1]\n",
    "    Y_train = np.array([1 if i==c1 else -1 for i in data[index][:,-1]]).reshape((-1,1))\n",
    "\n",
    "\n",
    "    df = pd.read_csv('./fashion_mnist/test.csv',header=None)\n",
    "    data = df.to_numpy()\n",
    "    index = np.logical_or(data[:,784]==c1 ,data[:,784]==c2)\n",
    "    X_test = data[index][:,:-1]\n",
    "    Y_test = np.array([1 if i==c1 else -1 for i in data[index][:,-1]]).reshape((-1,1))\n",
    "\n",
    "\n",
    "    df = pd.read_csv('./fashion_mnist/val.csv',header=None)\n",
    "    data = df.to_numpy()\n",
    "    index = np.logical_or(data[:,784]==c1 ,data[:,784]==c2)\n",
    "    X_val = data[index][:,:-1]\n",
    "    Y_val = np.array([1 if i==c1 else -1 for i in data[index][:,-1]]).reshape((-1,1))\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test, X_val, Y_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>DATA INPUT</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, X_val, Y_val = ReadInput(4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red' size = 6cm>Binary Classification</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - 1.a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearSVM_fit(X,Y):\n",
    "#     X = X_train/255\n",
    "#     Y = Y_train\n",
    "    G1 = np.diag(np.array([1]*Y.shape[0]))\n",
    "    G2 = np.diag(np.array([-1]*Y.shape[0]))\n",
    "    G = matrix(np.append(G1,G2,axis=0),tc='d')\n",
    "    c = 1\n",
    "    H = matrix(np.append(np.array([c]*Y.shape[0]),np.array([0]*Y.shape[0]),axis = 0),tc='d')\n",
    "    P = matrix(np.dot(X,X.T)*np.dot(Y,Y.T),tc='d')\n",
    "    Q = matrix(np.array([-1]*Y.shape[0]).T,tc='d')\n",
    "    A = matrix(Y.T,tc='d')\n",
    "    B = matrix(np.array(0).reshape((1,1)),tc='d')\n",
    "\n",
    "    sol = solvers.qp(P,Q,G,H,A,B)\n",
    "\n",
    "    alpha=np.array(sol['x'])\n",
    "\n",
    "    #calculating the support vectors given a threshold\n",
    "    threshold = 1e-10\n",
    "    data = np.append(X,Y,axis = 1)\n",
    "    data_with_alpha = np.append(data,alpha,axis = 1)\n",
    "    \n",
    "    supportVectors = data_with_alpha[np.where(data_with_alpha[:,-1] >= threshold)]\n",
    "    print(\"Total supports vectors\")\n",
    "    print(supportVectors.shape)\n",
    "    print('\\n')\n",
    "    # w = SUM( x*y*alpha )\n",
    "    w = np.sum(supportVectors[:,:-2]*supportVectors[:,-2].reshape((-1,1))*supportVectors[:,-1].reshape((-1,1)),axis=0).reshape((-1,1))\n",
    "\n",
    "#     pos_X = supportVectors[np.where(supportVectors[:,-2]==1)][:,:-2]\n",
    "#     neg_X = supportVectors[np.where(supportVectors[:,-2]==-1)][:,:-2]\n",
    "    XY = np.append(X,Y,axis=1)\n",
    "    pos_X = XY[np.where(XY[:,-1]==1)][:,:-1]\n",
    "    neg_X = XY[np.where(XY[:,-1]==-1)][:,:-1]\n",
    "                \n",
    "    print(\"aplha MIN \",alpha.max())\n",
    "    print(\"aplha MAX \",alpha.min())\n",
    "    b = -(np.dot(pos_X,w).min() + np.dot(neg_X,w).max())/2\n",
    "    print(b)\n",
    "    return w,b,supportVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearSVM_predict(X,Y,w,b):\n",
    "    pred = []\n",
    "    for x in X:\n",
    "        if (np.dot(w.T,x)+b) > 0:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(-1)\n",
    "\n",
    "    count =0\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == Y[i]:\n",
    "            count+=1\n",
    "    \n",
    "    print(\"Accurarcy is \",count*100/Y.shape[0],\" %\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>LEARNING</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.8144e+02 -7.2340e+03  4e+04  2e+00  1e-12\n",
      " 1: -1.0203e+02 -3.4492e+03  6e+03  3e-01  1e-12\n",
      " 2: -3.3534e+01 -9.1974e+02  2e+03  7e-02  6e-13\n",
      " 3: -1.1925e+01 -4.1859e+02  7e+02  2e-02  3e-13\n",
      " 4: -3.6847e+00 -1.7770e+02  3e+02  8e-03  1e-13\n",
      " 5: -1.2594e+00 -5.9907e+01  9e+01  2e-03  5e-14\n",
      " 6: -6.7211e-01 -2.5705e+01  4e+01  9e-04  3e-14\n",
      " 7: -4.1327e-01 -1.1925e+01  2e+01  3e-04  2e-14\n",
      " 8: -5.1263e-01 -5.5495e+00  6e+00  1e-04  1e-14\n",
      " 9: -5.7700e-01 -3.1645e+00  3e+00  4e-05  1e-14\n",
      "10: -7.0634e-01 -2.0084e+00  1e+00  3e-06  2e-14\n",
      "11: -9.3593e-01 -1.4177e+00  5e-01  7e-07  2e-14\n",
      "12: -1.0291e+00 -1.2146e+00  2e-01  4e-16  2e-14\n",
      "13: -1.0863e+00 -1.1319e+00  5e-02  4e-16  2e-14\n",
      "14: -1.1048e+00 -1.1100e+00  5e-03  5e-16  2e-14\n",
      "15: -1.1073e+00 -1.1074e+00  1e-04  5e-16  2e-14\n",
      "16: -1.1073e+00 -1.1073e+00  1e-06  6e-16  2e-14\n",
      "17: -1.1073e+00 -1.1073e+00  1e-08  5e-16  2e-14\n",
      "Optimal solution found.\n",
      "Total supports vectors\n",
      "(80, 786)\n",
      "\n",
      "\n",
      "aplha MIN  0.25238892773911575\n",
      "aplha MAX  2.1183016408705166e-13\n",
      "-0.49688298421661503\n",
      "total time for linear kernel SVM : 107.33704495429993\n"
     ]
    }
   ],
   "source": [
    "lk = time.time()\n",
    "w,b,supportVectors = LinearSVM_fit(X_train/255,Y_train)\n",
    "print('total time for linear kernel SVM :', time.time()-lk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>PREDICTING</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurarcy is  99.8  %\n",
      "Accurarcy is  99.6  %\n",
      "Accurarcy is  100.0  %\n"
     ]
    }
   ],
   "source": [
    "LinearSVM_predict(X_test/255,Y_test,w,b)\n",
    "LinearSVM_predict(X_val/255,Y_val,w,b)\n",
    "LinearSVM_predict(X_train/255,Y_train,w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - 1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianKernel(x,z,gamma):\n",
    "    L2norm= cdist(x,z,'euclidean')\n",
    "    return np.exp(-(L2norm**2)*gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def GausianSVM_fit(X,Y):\n",
    "    G1 = np.diag(np.array([1]*Y.shape[0]))\n",
    "    G2 = np.diag(np.array([-1]*Y.shape[0]))\n",
    "    G = matrix(np.append(G1,G2,axis=0),tc='d')\n",
    "    c = 1\n",
    "    H = matrix(np.append(np.array([c]*Y.shape[0]),np.array([0]*Y.shape[0]),axis = 0),tc='d')\n",
    "    Q = matrix(np.array([-1]*Y.shape[0]).T,tc='d')\n",
    "    A = matrix(Y.T,tc='d')\n",
    "    B = matrix(np.array(0).reshape((1,1)),tc='d')\n",
    "    IP = []\n",
    "    gamma = 0.05\n",
    "    \n",
    "    IP = GaussianKernel(X,X,gamma)\n",
    "\n",
    "    P = matrix(IP*np.dot(Y,Y.T),tc='d')\n",
    "    \n",
    "    #-----------------------------------\n",
    "    sol = solvers.qp(P,Q,G,H,A,B)\n",
    "    alpha=np.array(sol['x'])\n",
    "    #-----------------------------------\n",
    "    \n",
    "    print(\"aplha MIN \",alpha.max())\n",
    "    print(\"aplha MAX \",alpha.min())\n",
    "    \n",
    "    #calculating the support vectors given a threshold\n",
    "    threshold = 1e-5\n",
    "    data = np.append(X,Y,axis = 1)\n",
    "    data_with_alpha = np.append(data,alpha,axis = 1)\n",
    "\n",
    "    supportVectors = data_with_alpha[np.where(data_with_alpha[:,-1] >= threshold)]\n",
    "    print(\"Total supports vectors\")\n",
    "    print(supportVectors.shape)\n",
    "    print('\\n')\n",
    "\n",
    "    XY = np.append(X,Y,axis=1)\n",
    "    pos_X = XY[np.where(XY[:,-1]==1)][:,:-1]\n",
    "    neg_X = XY[np.where(XY[:,-1]==-1)][:,:-1]\n",
    "\n",
    "    #b\n",
    "    y_i = supportVectors[:,-2]\n",
    "    aplha_i = supportVectors[:,-1]\n",
    "    b1 = np.dot(GaussianKernel(supportVectors[:,:-2],pos_X,gamma).T,(aplha_i*y_i)).min()\n",
    "    \n",
    "    b2 = np.dot(GaussianKernel(supportVectors[:,:-2],neg_X,gamma).T,(aplha_i*y_i)).max()\n",
    "\n",
    "\n",
    "\n",
    "    b = -(b1+b2)/2\n",
    "    return b,supportVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GausianSVM_predict(X,Y,b,supportVectors):\n",
    "    gamma =0.05\n",
    "    \n",
    "    y_i = supportVectors[:,-2]\n",
    "    alpha_i =supportVectors[:,-1]\n",
    "    \n",
    "\n",
    "    wx = np.dot(GaussianKernel(supportVectors[:,:-2], X, gamma).T, (alpha_i*y_i)) \n",
    "\n",
    "    \n",
    "    prediction = wx+b\n",
    "\n",
    "    count = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        if (prediction[i] >0 and Y[i]==1) or (prediction[i] <=0 and Y[i]== -1):\n",
    "            count+=1\n",
    "    \n",
    "    print((count*100)/X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5598e+02 -6.9927e+03  3e+04  2e+00  1e-15\n",
      " 1: -8.8657e+01 -3.4857e+03  6e+03  2e-01  1e-15\n",
      " 2: -5.9446e+01 -7.3609e+02  8e+02  2e-02  2e-15\n",
      " 3: -1.0523e+02 -2.6151e+02  2e+02  4e-03  2e-15\n",
      " 4: -1.2171e+02 -1.8069e+02  6e+01  1e-03  1e-15\n",
      " 5: -1.2850e+02 -1.5673e+02  3e+01  8e-15  1e-15\n",
      " 6: -1.3314e+02 -1.4204e+02  9e+00  1e-14  1e-15\n",
      " 7: -1.3446e+02 -1.3849e+02  4e+00  6e-15  1e-15\n",
      " 8: -1.3538e+02 -1.3651e+02  1e+00  3e-15  1e-15\n",
      " 9: -1.3573e+02 -1.3581e+02  8e-02  1e-14  1e-15\n",
      "10: -1.3576e+02 -1.3576e+02  2e-03  2e-14  1e-15\n",
      "11: -1.3576e+02 -1.3576e+02  6e-05  3e-16  1e-15\n",
      "Optimal solution found.\n",
      "aplha MIN  0.9999999936128763\n",
      "aplha MAX  2.7568175816981765e-09\n",
      "Total supports vectors\n",
      "(1008, 786)\n",
      "\n",
      "\n",
      "91.32317876815796\n"
     ]
    }
   ],
   "source": [
    "s =time.time()\n",
    "b,supportVectors = GausianSVM_fit(X_train/255,Y_train)\n",
    "print(b)\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.8\n"
     ]
    }
   ],
   "source": [
    "GausianSVM_predict(X_test/255,Y_test,b,supportVectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.6\n"
     ]
    }
   ],
   "source": [
    "GausianSVM_predict(X_val/255,Y_val,b,supportVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "GausianSVM_predict(X_train/255,Y_train,b,supportVectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - 1.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SKlearn_LinearSVC(X_train, Y_train, X_test, Y_test, X_val, Y_val):\n",
    "    clf = SVC(random_state=0, tol=1e-5,kernel ='linear')\n",
    "    clf.fit(X_train/255,Y_train)\n",
    "    print(\"Intercept \",clf.intercept_)\n",
    "    print(\"Number of support Vectors \",clf.n_support_)\n",
    "\n",
    "    Y_pred_test=clf.predict(X_test/255)\n",
    "    Acc_test = accuracy_score(Y_test, Y_pred_test.ravel())*100\n",
    "    print(\"Accuracy over TEST data : \",Acc_test)\n",
    "\n",
    "    Y_pred_val=clf.predict(X_val/255)\n",
    "    Acc_val = accuracy_score(Y_val, Y_pred_val.ravel())*100\n",
    "    print(\"Accuracy over VALIDATION data : \",Acc_val)\n",
    "\n",
    "    \n",
    "        \n",
    "    Y_pred_train=clf.predict(X_train/255)\n",
    "    Acc_train = accuracy_score(Y_train, Y_pred_train.ravel())*100\n",
    "    print(\"Accuracy over TRAIN data : \",Acc_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "def SKlearn_SVC(X_train, Y_train, X_test, Y_test, X_val, Y_val):\n",
    "    clf = SVC(gamma=0.05,kernel='rbf')\n",
    "    clf.fit(X_train/255,Y_train)\n",
    "    print(\"Intercept \",clf.intercept_)\n",
    "    print(\"Number of support Vectors \",clf.n_support_)\n",
    "    \n",
    "    Y_pred_test=clf.predict(X_test/255)\n",
    "    Acc_test = accuracy_score(Y_test, Y_pred_test.ravel())*100\n",
    "    print(\"Accuracy over TEST data : \",Acc_test)\n",
    "\n",
    "    Y_pred_val=clf.predict(X_val/255)\n",
    "    Acc_val = accuracy_score(Y_val, Y_pred_val.ravel())*100\n",
    "    print(\"Accuracy over VALIDATION data : \",Acc_val)\n",
    "\n",
    "    \n",
    "        \n",
    "    Y_pred_train=clf.predict(X_train/255)\n",
    "    Acc_train = accuracy_score(Y_train, Y_pred_train.ravel())*100\n",
    "    print(\"Accuracy over TRAIN data : \",Acc_train)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept  [-0.49688327]\n",
      "Number of support Vectors  [57 16]\n",
      "Accuracy over TEST data :  99.8\n",
      "Accuracy over VALIDATION data :  99.6\n",
      "Accuracy over TRAIN data :  100.0\n"
     ]
    }
   ],
   "source": [
    "SKlearn_LinearSVC(X_train, Y_train, X_test, Y_test, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept  [-0.32537323]\n",
      "Number of support Vectors  [594 387]\n",
      "Accuracy over TEST data :  99.6\n",
      "Accuracy over VALIDATION data :  99.6\n",
      "Accuracy over TRAIN data :  100.0\n"
     ]
    }
   ],
   "source": [
    "SKlearn_SVC(X_train, Y_train, X_test, Y_test, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red' size = 6cm>Multi-Class Classification</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - 2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiClass_fit():\n",
    "    for i in range(10):\n",
    "        for j in tqdm(range(i+1,10)):\n",
    "            X_train, Y_train, X_test, Y_test, X_val, Y_val = ReadInput(i,j)\n",
    "            b,supportVectors = GausianSVM_fit(X_train/255,Y_train)\n",
    "            model = [b,supportVectors]\n",
    "            version = \"model\"+str(i)+str(j)\n",
    "            with open(version,'wb') as f:\n",
    "                pickle.dump(model,f)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiClass_predict(X,Y):\n",
    "    m = X.shape[0]\n",
    "    gamma= 0.05\n",
    "    count_matrix = np.zeros((m,10))\n",
    "    score_matrix = np.zeros((m,10))\n",
    "\n",
    "    for i in tqdm(range(10)):\n",
    "        for j in range(i+1,10):\n",
    "            modelNo = \"model\"+str(i)+str(j)\n",
    "            with open('Models/'+modelNo,'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            b = model[0]\n",
    "            supportVectors = model[1]\n",
    "\n",
    "            y_i = supportVectors[:,-2]\n",
    "            alpha_i =supportVectors[:,-1]\n",
    "\n",
    "            wx = np.dot(GaussianKernel(supportVectors[:,:-2], X, gamma).T, (alpha_i*y_i)) \n",
    "\n",
    "            prediction_score = wx+b\n",
    "\n",
    "            for k in range(X.shape[0]):\n",
    "\n",
    "                if prediction_score[k] > 0:\n",
    "                    score_matrix[k,i] += abs((prediction_score[k]))\n",
    "                    count_matrix[k,i]+=1\n",
    "                else:\n",
    "                    score_matrix[k,j] += abs((prediction_score[k]))\n",
    "                    count_matrix[k,j]+=1\n",
    "\n",
    "\n",
    "    final_pred = []\n",
    "    correct_pred_count = 0\n",
    "    confusion_matrix = np.zeros((10,10))\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        class_index = []\n",
    "        max_value = count_matrix[i,:].max()\n",
    "        for j in range(10):\n",
    "            if max_value == count_matrix[i,j]:\n",
    "                class_index.append(j)\n",
    "        if len(class_index)==1:\n",
    "            final_pred.append(class_index[0])\n",
    "            if final_pred[i] == Y[i]:\n",
    "                correct_pred_count+=1\n",
    "                confusion_matrix[int(Y[i]),int(Y[i])]+=1\n",
    "            else:\n",
    "                confusion_matrix[int(final_pred[i]),int(Y[i])]+=1\n",
    "                \n",
    "        else:\n",
    "            score_value = -math.inf\n",
    "            for k in class_index:\n",
    "                if score_matrix[i,k] > score_value:\n",
    "                    score_value = score_matrix[i,k]\n",
    "                    index = k\n",
    "            final_pred.append(index)\n",
    "            if final_pred[i] == Y[i]:\n",
    "                correct_pred_count+=1\n",
    "                confusion_matrix[int(Y[i]),int(Y[i])]+=1\n",
    "            else:\n",
    "                confusion_matrix[int(final_pred[i]),int(Y[i])]+=1\n",
    "                \n",
    "    print(\"\\n\")\n",
    "    print(\"accuracy is \",(correct_pred_count*100)/Y.shape[0])\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:06<00:00, 18.65s/it]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 52177.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "accuracy is  85.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('fashion_mnist/test.csv',header=None)\n",
    "data = df.to_numpy()\n",
    "X_test = data[:,:-1]\n",
    "Y_test = data[:,-1]\n",
    "X_test =X_test/255\n",
    "confusion_matrix_2a_test = MultiClass_predict(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:31<00:00,  9.10s/it]\n",
      "100%|██████████| 2500/2500 [00:00<00:00, 36210.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "accuracy is  84.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('fashion_mnist/val.csv',header=None)\n",
    "data = df.to_numpy()\n",
    "X_val = data[:,:-1]\n",
    "Y_val = data[:,-1]\n",
    "X_val =X_val/255\n",
    "confusion_matrix_2a_val = MultiClass_predict(X_val,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - 2.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5cm color = red>Multi-class SVM: Using the Scikit SVM </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SKlearnOVO_fit(X,Y):\n",
    "    \n",
    "    for i in range(10):\n",
    "        for j in range(i+1,10):\n",
    "            model = SVC(gamma=0.05,kernel='rbf')\n",
    "            model.fit(X,Y)\n",
    "            Y_pred = model.predict(X)\n",
    "            score = model.decision_function(X)\n",
    "            model_parameters = [Y_pred, score]\n",
    "            version = \"SKlearn_Model\"+str(i)+str(j)\n",
    "            with open() as f:\n",
    "                pickle.dump(model_parameters,f)\n",
    "                \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SKlearn_MultiClass_predict(X,Y):\n",
    "    m = X.shape[0]\n",
    "    gamma= 0.05\n",
    "    count_matrix = np.zeros((m,10))\n",
    "    score_matrix = np.zeros((m,10))\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in tqdm(range(i+1,10)):\n",
    "            modelNo = \"SKlearn_Model\"+str(i)+str(j)\n",
    "            with open('Models/'+modelNo,'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            \n",
    "            prediction_score = model.decision_function(X)\n",
    "            \n",
    "\n",
    "            for k in range(X.shape[0]):\n",
    "\n",
    "                if prediction_score[k] > 0:\n",
    "                    score_matrix[k,i] += abs((prediction_score[k]))\n",
    "                    count_matrix[k,i]+=1\n",
    "                else:\n",
    "                    score_matrix[k,j] += abs((prediction_score[k]))\n",
    "                    count_matrix[k,j]+=1\n",
    "\n",
    "\n",
    "\n",
    "    final_pred = []\n",
    "    correct_pred_count = 0\n",
    "    confusion_matrix = np.zeros((10,10))\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        class_index = []\n",
    "        max_value = count_matrix[i,:].max()\n",
    "        for j in range(10):\n",
    "            if max_value == count_matrix[i,j]:\n",
    "                class_index.append(j)\n",
    "        if len(class_index)==1:\n",
    "            final_pred.append(class_index[0])\n",
    "            if final_pred[i] == Y[i]:\n",
    "                correct_pred_count+=1\n",
    "                confusion_matrix[int(Y[i]),int(Y[i])]+=1\n",
    "            else:\n",
    "                confusion_matrix[int(final_pred[i]),int(Y[i])]+=1\n",
    "        else:\n",
    "            score_value = -math.inf\n",
    "            for k in class_index:\n",
    "                if score_matrix[i,k] > score_value:\n",
    "                    score_value = score_matrix[i,k]\n",
    "                    index = k\n",
    "            final_pred.append(index)\n",
    "            if final_pred[i] == Y[i]:\n",
    "                correct_pred_count+=1\n",
    "                confusion_matrix[int(Y[i]),int(Y[i])]+=1\n",
    "            else:\n",
    "                confusion_matrix[int(final_pred[i]),int(Y[i])]+=1\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"accuracy is \",(correct_pred_count*100)/Y.shape[0])\n",
    "    return confusion_matrix\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:08<00:00,  7.60s/it]\n",
      "100%|██████████| 8/8 [00:39<00:00,  4.95s/it]\n",
      "100%|██████████| 7/7 [01:02<00:00,  8.96s/it]\n",
      "100%|██████████| 6/6 [00:39<00:00,  6.63s/it]\n",
      "100%|██████████| 5/5 [00:38<00:00,  7.61s/it]\n",
      "100%|██████████| 4/4 [00:34<00:00,  8.50s/it]\n",
      "100%|██████████| 3/3 [00:20<00:00,  6.73s/it]\n",
      "100%|██████████| 2/2 [00:14<00:00,  7.36s/it]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.96s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 75658.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "accuracy is  88.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('fashion_mnist/test.csv',header=None)\n",
    "data = df.to_numpy()\n",
    "X_test = data[:,:-1]\n",
    "Y_test = data[:,-1].astype(int)\n",
    "confusion_matrix_2b_test = SKlearn_MultiClass_predict(X_test/255,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:33<00:00,  3.72s/it]\n",
      "100%|██████████| 8/8 [00:19<00:00,  2.41s/it]\n",
      "100%|██████████| 7/7 [00:30<00:00,  4.36s/it]\n",
      "100%|██████████| 6/6 [00:19<00:00,  3.25s/it]\n",
      "100%|██████████| 5/5 [00:18<00:00,  3.73s/it]\n",
      "100%|██████████| 4/4 [00:16<00:00,  4.19s/it]\n",
      "100%|██████████| 3/3 [00:09<00:00,  3.26s/it]\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.50s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 2500/2500 [00:00<00:00, 65543.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "accuracy is  87.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('fashion_mnist/val.csv',header=None)\n",
    "data = df.to_numpy()\n",
    "X_val = data[:,:-1]\n",
    "Y_val = data[:,-1].astype(int)\n",
    "confusion_matrix_2b_val = SKlearn_MultiClass_predict(X_val/255,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - 2.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color =red size =5cm>Confusion Matrix</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "def ConfusionMatrix(confusionMatrix,title):\n",
    "    df_cm = pd.DataFrame(confusionMatrix, index = [i for i in range(10)],\n",
    "                      columns = [i for i in range(10)], dtype=int)\n",
    "    plt.figure(figsize = (10,8))\n",
    "    sn.heatmap(df_cm, annot=True,fmt='d')\n",
    "    plt.xlabel(\"ACTUAL VALUE\")\n",
    "    plt.ylabel(\"PREDICTED VALUE\")\n",
    "    plt.title(title,color = 'red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix(confusion_matrix_2a_test,\"Gaussian Kernel: Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix(confusion_matrix_2a_val,\"Gaussian Kernel: Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix(confusion_matrix_2b_test,\"Scikit SVM Kernel: Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix(confusion_matrix_2b_val,\"Scikit SVM Kernel: Val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - 2.d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color =red size =5cm>5-fold cross validation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./fashion_mnist/train.csv',header=None)\n",
    "data = df.to_numpy()\n",
    "X_train = data[:,:-1]/255\n",
    "Y_train = data[:,-1].astype(int)\n",
    "\n",
    "df = pd.read_csv('./fashion_mnist/test.csv',header=None)\n",
    "data = df.to_numpy()\n",
    "X_test = data[:,:-1]/255\n",
    "Y_test = data[:,-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_parameter = [1e-5,1e-3,1,5,10]\n",
    "# k_fold = KFold(n_splits=5)\n",
    "sfK_fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanscoresList = []\n",
    "scoresMatrix = []\n",
    "for c in tqdm(C_parameter):\n",
    "    SVCmodel = SVC(C=c, kernel='rbf',gamma=0.05)\n",
    "    scores = cross_val_score(SVCmodel, X_train, Y_train, cv=sfK_fold, n_jobs=-1)\n",
    "    scoresMatrix.append(scores)\n",
    "    meanScore = np.mean(scores)\n",
    "    meanscoresList.append(meanScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ [0.5664444444444444,\n",
    " 0.5664444444444444,\n",
    " 0.8787111111111111,\n",
    " 0.8844,\n",
    " 0.8842666666666666] __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel,delayed\n",
    "def svcParameter(c):\n",
    "    SVCmodel = SVC(C=c, kernel='rbf',gamma=0.05,decision_function_shape='ovo')\n",
    "    SVCmodel.fit(X_train,Y_train)\n",
    "    Y_pred_test = SVCmodel.predict(X_test)\n",
    "    Acc_test = accuracy_score(Y_test, Y_pred_test)*100\n",
    "    print(\"Accuracy over TEST data : \",Acc_test)\n",
    "    return Acc_test\n",
    "\n",
    " \n",
    "\n",
    "acc_val = Parallel(n_jobs=5)(delayed(svcParameter)(i) for i in C_parameter )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# acc_val = [57.36, 57.36, 88.08, 88.28, 88.24]  20 MINUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_score = np.array([0.5664444444444444, 0.5664444444444444, 0.8787111111111111, 0.8844, 0.8842666666666666])*100\n",
    "Acc_val = np.array([57.36, 57.36, 88.08, 88.28, 88.24] )\n",
    "%matplotlib qt\n",
    "x_axis = np.log10([1e-5, 1e-3, 1, 5, 10])\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('Scores %')\n",
    "ax.set_xlabel('Differnt C-parameter Values')\n",
    "ax.set_title('K-fold Cross_validation')\n",
    "# ax.set_xticklabels(x_axis)\n",
    "plt.xticks(x_axis)\n",
    "plt.plot(x_axis,Model_score,label='Train scores', marker='o')\n",
    "plt.plot(x_axis,Acc_val,label ='Test_accuracy', marker='x')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
