{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xclib.data import data_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/.local/lib/python3.6/site-packages/xclib-0.96-py3.6-linux-x86_64.egg/xclib/data/data_utils.py:173: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    }
   ],
   "source": [
    "# Read sparse file\n",
    "train_x = data_utils.read_sparse_file('ass3_parta_data/train_x.txt', force_header=True)\n",
    "train_x = np.array(train_x.toarray(),dtype =int)\n",
    "train_y = pd.read_csv('ass3_parta_data/train_y.txt', sep=\"\\n\", header=None).to_numpy()\n",
    "\n",
    "test_x = data_utils.read_sparse_file('ass3_parta_data/test_x.txt', force_header=True)\n",
    "test_x = np.array(test_x.toarray(),dtype =int)\n",
    "test_y = pd.read_csv('ass3_parta_data/test_y.txt', sep=\"\\n\", header=None).to_numpy()\n",
    "\n",
    "val_x = data_utils.read_sparse_file('ass3_parta_data/valid_x.txt', force_header=True)\n",
    "val_x = np.array(val_x.toarray(),dtype =int)\n",
    "val_y = pd.read_csv('ass3_parta_data/valid_y.txt', sep=\"\\n\", header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    \"\"\"\n",
    "    Calculates the uncertanity of data :\n",
    "    sparse distibuted data low entropy\n",
    "    mixed distibuted data high entropy\n",
    "    \"\"\"\n",
    "    totaldata = data.shape[0]\n",
    "    \n",
    "    Totalpositive = np.sum(data[:,-1]==1)\n",
    "    Totalnegative = np.sum(data[:,-1]==0)\n",
    "    H = 0 \n",
    "    \n",
    "    # When only one class of data -> Pure\n",
    "    if Totalpositive ==0 or Totalnegative ==0:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        positive_ratio = Totalpositive/totaldata\n",
    "        negative_ratio = Totalnegative/totaldata\n",
    "        H = -positive_ratio * log2(positive_ratio) + (-negative_ratio * log2(negative_ratio))\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(data,true_data_index,false_data_index,H):\n",
    "    \"\"\"\n",
    "    Takes data, entropy of that data (H)\n",
    "    as well as a col number to find info_gain \n",
    "    if we split on that col median\n",
    "    \"\"\"\n",
    "    totalDataSize =data.shape[0]\n",
    "    true_data = data[true_data_index]\n",
    "    false_data = data[false_data_index]\n",
    "    \n",
    "    true_branch_ratio = true_data.shape[0]/totalDataSize\n",
    "    false_branch_ratio = false_data.shape[0]/totalDataSize  \n",
    "\n",
    "    if true_branch_ratio == 0 or false_branch_ratio ==0:\n",
    "        return 0\n",
    "    \n",
    "    trueEntropy  = entropy(true_data)\n",
    "    falseEntropy = entropy(false_data)\n",
    "    \n",
    "    I = H - ((true_branch_ratio * trueEntropy) + (false_branch_ratio * falseEntropy))\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(data,H):\n",
    "    \n",
    "    best_info_gain = -1\n",
    "    best_attr = -1\n",
    "#     split_median = -1\n",
    "    trueIndex = None\n",
    "    falseIndex = None\n",
    "    # consider all attributes except the last one i.e label *y*\n",
    "    medianList  = np.median(data[:,:-1],axis =0)\n",
    "\n",
    "    \n",
    "    for colIndex, median in enumerate(medianList):\n",
    "        \n",
    "        true_data_index = np.where(data[:,colIndex] <= median)\n",
    "        false_data_index = np.where(data[:,colIndex] > median)\n",
    "\n",
    "        \n",
    "        IG = info_gain(data,true_data_index,false_data_index,H)\n",
    "\n",
    "        if IG > best_info_gain:\n",
    "            best_info_gain = IG\n",
    "            best_attr = colIndex\n",
    "            split_median = median\n",
    "            trueIndex = true_data_index\n",
    "            falseIndex = false_data_index\n",
    "\n",
    "    return best_attr, split_median, trueIndex,falseIndex, best_info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classCount(data):\n",
    "    count =dict()\n",
    "    count[1] = np.sum(data[:,-1]==1)\n",
    "    count[0] = np.sum(data[:,-1]==0)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_nodes:\n",
    "    \"\"\"\n",
    "    Internal nodes where we ask questions \n",
    "    to split the node further if possible\n",
    "    **Also hold the reference to the 2 child branches**\n",
    "    \"\"\"\n",
    "    total_decision_nodes = 0\n",
    "    depth = 0\n",
    "    def __init__(self,entropy, best_attr, split_median, depth):\n",
    "        self.entropy = entropy\n",
    "        self.best_attr = best_attr\n",
    "        self.split_median = split_median\n",
    "        self.depth = depth\n",
    "        \n",
    "        Decision_nodes.total_decision_nodes+=1\n",
    "        if depth > Decision_nodes.depth:\n",
    "            Decision_nodes.depth = depth\n",
    "\n",
    "    def assignLabel(self,label):\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "\n",
    "    total_leaf_nodes = 0\n",
    "    def __init__(self,data,depth):\n",
    "        self.prediction = classCount(data)\n",
    "        self.depth = depth\n",
    "        if self.prediction[1] > self.prediction[0]:\n",
    "            self.label = 1\n",
    "        else:\n",
    "            self.label = 0\n",
    "        LeafNode.total_leaf_nodes+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_tree(data,depth):\n",
    "\n",
    "    \"\"\"\n",
    "    Recursively build the tree\n",
    "    and stop when there is almost no Inforamtion_gain\n",
    "    \"\"\"\n",
    "    H = entropy(data)\n",
    "    \n",
    "\n",
    "    best_attr, split_median, trueIndex, falseIndex, best_info_gain =  best_split(data,H)\n",
    " \n",
    "    # base case to stop recursion\n",
    " \n",
    "    if H ==0 or best_attr == -1 or best_info_gain <= 0:\n",
    "        return LeafNode(data,depth)\n",
    "    \n",
    "    root = Decision_nodes(H,best_attr, split_median, depth)\n",
    "\n",
    "    true_branch = data[trueIndex]\n",
    "    false_branch = data[falseIndex]\n",
    "    \n",
    "    if true_branch.shape[0] ==0 or false_branch.shape[0]==0:\n",
    "        return LeafNode(data,depth)\n",
    "    \n",
    "    root.leftChild = Build_tree(true_branch,depth+1)\n",
    "    root.rightChild = Build_tree(false_branch,depth+1)\n",
    "    return root "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548.6520748138428\n"
     ]
    }
   ],
   "source": [
    "train_data = np.append(train_x,train_y,axis=1)\n",
    "s = time.time()\n",
    "root = Build_tree(train_data,0)\n",
    "print(time.time() -s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9988"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Decision_nodes.depth)\n",
    "Decision_nodes.total_decision_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9989"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeafNode.total_leaf_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row, node):\n",
    "    \"\"\"See the 'rules of recursion' above.\"\"\"\n",
    "\n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, LeafNode):\n",
    "        return node.label\n",
    "\n",
    "    col = node.best_attr\n",
    "    median = node.split_median\n",
    "    if row[col] <= median:\n",
    "        return classify(row, node.leftChild)\n",
    "    else:\n",
    "        return classify(row, node.rightChild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for row in train_x:\n",
    "    prediction.append(classify(row,root))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.43932440158855\n"
     ]
    }
   ],
   "source": [
    "match=0\n",
    "for i in range(len(prediction)):\n",
    "    if train_y[i]==prediction[i]:\n",
    "        match+=1\n",
    "print((match*100)/len(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
