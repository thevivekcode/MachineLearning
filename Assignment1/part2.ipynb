{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as animation\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputData():\n",
    "    df = pd.read_csv(\"./data/q2/q2test.csv\")\n",
    "    X_0 = np.ones((len(df),1))\n",
    "    X1X2Y = df.to_numpy()\n",
    "    X0X1X2Y = np.append(X_0,X1X2Y, axis=1)\n",
    "    np.random.shuffle(X0X1X2Y)  #shuffling data to make it random for better distribution\n",
    "    return X0X1X2Y\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleData():\n",
    "    Stheta = np.reshape(np.array([3,1,2]),(3,1))\n",
    "    SX_0 = np.ones((1000000))\n",
    "    SX_1 = np.random.normal(size = 1000000, loc = 3, scale = 2) # loc = mean scale = standard deviation\n",
    "    SX_2 = np.random.normal(size = 1000000, loc = -1, scale = 2)\n",
    "    SX = np.reshape(np.array([SX_0,SX_1,SX_2]).T,(-1,3) ) # creating design matrix of sample data\n",
    "    hypoT = np.dot(SX,Stheta)\n",
    "#     print(\"hypoThesis shape\")\n",
    "#     print(hypoT.shape)\n",
    "    SY = np.reshape(np.random.normal(size = 1000000, loc = hypoT.T , scale = math.sqrt(2)),(-1,1))\n",
    "    SX0X1X2Y = np.append(SX,SY,axis=1)\n",
    "#     print(SX0X1X2Y)\n",
    "    np.random.shuffle(SX0X1X2Y)\n",
    "#     print(SX0X1X2Y)\n",
    "#     plot to visualize the generated sample\n",
    "#     plt.scatter(SX0X1X2Y[:,1:2],SX0X1X2Y[:,3:4])\n",
    "#     plt.scatter(SX0X1X2Y[:,2:3],SX0X1X2Y[:,3:4])\n",
    "#     plt.show()\n",
    "\n",
    "    return SX0X1X2Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFuction(SX0X1X2Y,theta):\n",
    "    hypothesis = np.dot(SX0X1X2Y[:,0:3],np.array(theta))\n",
    "    hypothesis = np.reshape(hypothesis,(-1,1))\n",
    "    error = SX0X1X2Y[:,3:4]-hypothesis\n",
    "    errorSquared =error**2\n",
    "    examples = SX0X1X2Y.shape[0] #X.shape[0] represents number of training example\n",
    "    return np.sum(errorSquared)/(2*examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = sampleData()\n",
    "# print(a)\n",
    "# costFuction(a,[3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientFunction(SX0X1X2Y,theta):\n",
    "    error = np.reshape(np.reshape(np.dot(SX0X1X2Y[:,0:3],np.array(theta)),(-1,1)) - SX0X1X2Y[:,3:4],(-1,1))  # h(X) -y\n",
    "    grad_cost = np.zeros((3,1))\n",
    "    grad_cost[0] = np.sum(error*SX0X1X2Y[:,0:1])/(SX0X1X2Y.shape[0])\n",
    "    grad_cost[1] = np.sum(error*SX0X1X2Y[:,1:2])/(SX0X1X2Y.shape[0])\n",
    "    grad_cost[2] = np.sum(error*SX0X1X2Y[:,2:3])/(SX0X1X2Y.shape[0])\n",
    "    return grad_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SX0X1X2Y = sampleData()\n",
    "# gradientFunction(SX0X1X2Y,[3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement Stochastic gradient descent unitil it converges\n",
    "\n",
    "def stochasticGradientDescent(SX0X1X2Y):\n",
    "    \n",
    "    \n",
    "    \n",
    "    theta = np.zeros((3,1))  # initializing theta vector\n",
    "\n",
    "    learningRate = 1e-3\n",
    "    \n",
    "    \n",
    "    costPlot = [] # list for plot of costfunction\n",
    "    thetaList0 = []\n",
    "    thetaList1 = []\n",
    "    thetaList2 = []\n",
    "    \n",
    "    batchSize = 1  # size of batch on which we would run SGD\n",
    "    Batch_SX0X1X2Y = np.reshape(SX0X1X2Y,(-1,batchSize,4))\n",
    "    \n",
    "    print(\"batch size is {}\".format(batchSize))\n",
    "\n",
    "\n",
    "    stopping_criteria  = 0\n",
    "    if len(Batch_SX0X1X2Y) <=10000:\n",
    "        stopping_criteria = 1e-3\n",
    "    else:\n",
    "        stopping_criteria = 1e-4\n",
    "        \n",
    "#     repeatIteration = 0\n",
    "#     if len(Batch_SX0X1X2Y) <=10000:\n",
    "#         repeatIteration = 100\n",
    "#     else:\n",
    "#         repeatIteration = 1000\n",
    "    \n",
    "    print(\"stopping_criteria is  {}\".format(stopping_criteria))\n",
    "    \n",
    "    count = 0\n",
    "    costNew = 0\n",
    "    cost = 0\n",
    "    flag = 0\n",
    "    while(True):\n",
    "    \n",
    "        for i in Batch_SX0X1X2Y:\n",
    "            \n",
    "            if flag ==1:\n",
    "                cost += costFuction(i,theta)\n",
    "                count += 1\n",
    "                if count == 2000:\n",
    "                    costOld = costNew\n",
    "                    costNew = cost/2000\n",
    "                    print(abs(costOld - costNew))\n",
    "    #                 print(theta)\n",
    "                    if abs(costOld - costNew) <= stopping_criteria:\n",
    "                        return theta\n",
    "                    cost = 0\n",
    "                    count = 0\n",
    "            theta -= learningRate * gradientFunction(i,theta)\n",
    "        flag = 1\n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size is 1\n",
      "stopping_criteria is  0.0001\n",
      "0.9908384028087218\n",
      "0.0034404919263104627\n",
      "0.056382116191967535\n",
      "0.06147629049678116\n",
      "0.02158610390279614\n",
      "0.05983189357984953\n",
      "0.007558356046357684\n",
      "0.0339516793497745\n",
      "0.02292640266073076\n",
      "0.05488451896858859\n",
      "0.01762210277014231\n",
      "0.0328066235597857\n",
      "0.06646592279234442\n",
      "0.051097634846236306\n",
      "0.058960970687020886\n",
      "0.05528628143139147\n",
      "0.00847612866825953\n",
      "0.03868299526874408\n",
      "0.020278755040174512\n",
      "0.026071548744044937\n",
      "0.02484275889342158\n",
      "0.004454248379795134\n",
      "0.01944378946006209\n",
      "0.009591369014857909\n",
      "0.027693204408470784\n",
      "0.011344025065979757\n",
      "0.03947590616422991\n",
      "0.007419732558714975\n",
      "0.04082355466371257\n",
      "0.00345460328055891\n",
      "0.04467392109795587\n",
      "0.08387673360146208\n",
      "0.09243295901172988\n",
      "0.02972084666479069\n",
      "0.03500794609572422\n",
      "0.047886586637870154\n",
      "0.06206880633441725\n",
      "0.0009457601183353592\n",
      "0.04088853708135254\n",
      "0.10788886100584227\n",
      "0.04979308273122662\n",
      "0.011287597308897057\n",
      "0.007629528883437264\n",
      "0.010604709742642826\n",
      "0.06253740872614522\n",
      "0.054345000311029845\n",
      "0.04074182788474967\n",
      "0.002037625833043233\n",
      "0.05767115905164333\n",
      "0.05912576573635919\n",
      "0.005895475755434143\n",
      "0.001237818774160404\n",
      "0.025061482624348486\n",
      "0.03427797532182586\n",
      "0.08456735739577415\n",
      "0.06260268973986394\n",
      "0.011147476806365741\n",
      "0.043023701392794544\n",
      "0.036271770847095874\n",
      "0.014770591173109193\n",
      "0.10977135219317968\n",
      "0.13999075029400554\n",
      "0.09849015256239746\n",
      "0.08943323309860152\n",
      "0.08284090105318487\n",
      "0.07828166531317315\n",
      "0.0007249728451594883\n",
      "0.06296827638623259\n",
      "0.040334678498126775\n",
      "0.02297202927993036\n",
      "0.02241908236705814\n",
      "0.003654777853033253\n",
      "0.03656793775081657\n",
      "0.017033823883176646\n",
      "0.05375254000315066\n",
      "0.012859339278247228\n",
      "0.001624337894090444\n",
      "0.02697364731866847\n",
      "0.03982445515925348\n",
      "0.03212804601687136\n",
      "0.0018357193281999251\n",
      "0.02976435677717637\n",
      "0.0391363230132451\n",
      "0.016877497927095586\n",
      "0.03739062348965572\n",
      "0.0013446362844908855\n",
      "0.004005945544670375\n",
      "0.030506631503611326\n",
      "0.07621730421748263\n",
      "0.04230346972523635\n",
      "0.006969982163965827\n",
      "0.03880909531658949\n",
      "0.08083179840076093\n",
      "0.09140548835767892\n",
      "2.04640358432151e-05\n",
      "theta is [[3.02194175]\n",
      " [0.99873819]\n",
      " [1.95187647]]\n",
      "48.06954216957092\n"
     ]
    }
   ],
   "source": [
    "SX0X1X2Y = sampleData()\n",
    "startTime = time()\n",
    "theta = stochasticGradientDescent(SX0X1X2Y)\n",
    "print(\"theta is {}\".format(theta))\n",
    "endTime = time() -startTime\n",
    "print(endTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SX0X1X2Y = sampleData()\n",
    "# theta = [3,1,2]\n",
    "# costFuction(SX0X1X2Y,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([1,2,3,4,5])\n",
    "np.random.shuffle(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
