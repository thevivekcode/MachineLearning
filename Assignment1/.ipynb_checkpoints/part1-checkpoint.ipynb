{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputData():\n",
    "    dfX = pd.read_csv(\"./data/q1/linearX.csv\",usecols=[0],names=[\"X\"],header=None)\n",
    "    inputListX=dfX['X'].tolist()\n",
    "    dfY = pd.read_csv(\"./data/q1/linearY.csv\",usecols=[0],names=[\"Y\"],header=None)\n",
    "    inputListY=dfY['Y'].tolist()\n",
    "    return inputListX,inputListY\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize function (x-mean)/std for each value in input listX\n",
    "\n",
    "def normalize(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    data = data -mean\n",
    "    data = data/std\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch Gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: creating input DATA\n",
    "#         Making Design matrix \"X\" with X0=1\n",
    "\n",
    "def align():\n",
    "    \n",
    "    (inputListX,inputListY) = inputData()\n",
    "    numpyListX = normalize(np.reshape(np.array(inputListX),(-1,1)))\n",
    "    numpyListY = np.reshape(np.array(inputListY),(-1,1))\n",
    "    \n",
    "    data = np.append( numpyListX,numpyListY, axis = 1)\n",
    "\n",
    "    np.random.shuffle(data)  #shuffling data to make it random for better distribution\n",
    "\n",
    "    x = data[:, 0 : 1]  #copy all rows and only copy zeroth col [0,1)\n",
    "    y = data[:, 1 : 2]  #copy all rows and only copy first col [1,2)\n",
    "    ones = np.ones((x.shape[0], 1))\n",
    "    X = np.append(ones, x, axis = 1)\n",
    "    return x,y,X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: define a cost function\n",
    "\n",
    "def costFuction(y,X,theta):\n",
    "    hypothesis = np.dot(X,np.array(theta))\n",
    "    hypothesis = np.reshape(hypothesis,(100,1))\n",
    "    error = y-hypothesis\n",
    "    errorSquared =error**2\n",
    "    examples = X.shape[0] #X.shape[0] represents number of training example\n",
    "    return np.sum(errorSquared)/(2*examples) \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4: define a gradient function\n",
    "\n",
    "def gradientFunction(X,y,theta):\n",
    "    error = np.reshape(np.dot(X,theta),(-1,1)) - y  # h(X) -y\n",
    "    np.reshape(error,(-1,1))\n",
    "    grad_cost = np.zeros((2,1))\n",
    "    grad_cost[0] = np.sum(error*X[:,0:1])/(X.shape[0])\n",
    "    grad_cost[1] = np.sum(error*X[:,1:2])/(X.shape[0])\n",
    "    return grad_cost\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement gradient descent unitil it converges\n",
    "\n",
    "def gradientDescent(x,y,X):\n",
    "    \n",
    "#     (x,y,X) = align()\n",
    "    \n",
    "    theta = np.zeros((X.shape[1],1))  # initializing theta vector\n",
    "\n",
    "    learningRate = 0.025\n",
    "    \n",
    "    \n",
    "    costPlot = [] # list for plot of costfunction\n",
    "    thetaList0 =[]\n",
    "    thetaList1 =[]\n",
    "    \n",
    "    #first iteration to implement do while \n",
    "    oldTheta = theta.copy()  \n",
    "    thetaList0 = np.append(thetaList0,theta[0:1,:])\n",
    "    thetaList1 = np.append(thetaList1,theta[1:2,:])\n",
    "    \n",
    "    theta -= learningRate*gradientFunction(X,y,theta) #theta(t+1)\n",
    "    thetaList0 = np.append(thetaList0,theta[0:1,:])\n",
    "    thetaList1 = np.append(thetaList1,theta[1:2,:])\n",
    "    costOld = costFuction(y,X,oldTheta)\n",
    "    costNew = costFuction(y,X,theta)\n",
    "    costPlot.append(costOld)\n",
    "    costPlot.append(costNew)\n",
    "    \n",
    "    while(abs(costNew - costOld) > 1e-15 ):\n",
    "        costOld = costNew.copy()\n",
    "        oldTheta = theta.copy()\n",
    "        theta -= learningRate*gradientFunction(X,y,theta)\n",
    "        costNew = costFuction(y,X,theta)\n",
    "        thetaList0 = np.append(thetaList0,theta[0:1,:])\n",
    "        thetaList1 = np.append(thetaList1,theta[1:2,:])\n",
    "        costPlot.append(costNew)\n",
    "    return x,y,X,theta,costPlot,thetaList0,thetaList1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x,y,X,theta,costPlot,thetaList0,thetaList1):\n",
    "    \n",
    "#     ( x,y,X,theta,costPlot,thetaList0,thetaList1) = gradientDescent()\n",
    "    \n",
    "    # plot data point and hypothesis\n",
    "    plt.scatter(x,y)\n",
    "    hypo, = plt.plot(x,theta[0]+x*theta[1] , color='r')\n",
    "    plt.title(\"linear regression\" )\n",
    "    plt.show()\n",
    "\n",
    "    #plot cost function\n",
    "#     twoDplot, = plt.plot(costPlot)\n",
    "    plt.show(block = False)\n",
    "    return  hypo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surface_plot(x,y,X,theta,costPlot,thetaList0,thetaList1):\n",
    "#     %matplotlib qt\n",
    "#     (x,y,X) = align()\n",
    "#     ( x,y,X,theta,costPlot,thetaList0,thetaList1) = gradientDescent(x,y,X)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    #create 100 different theta values for plotting plot_surface\n",
    "    th0 = np.linspace(theta[0:1,:]-1,theta[0:1,:]+1,100)\n",
    "    th1 = np.linspace(theta[1:2,:]-1,theta[1:2,:]+1,100)\n",
    "\n",
    "    \n",
    "    # meshGrid to create all possible pairs od theta in X and Y axis\n",
    "    theta_0,theta_1 = np.meshgrid(th0,th1)\n",
    "\n",
    "    # calculating CostFun for all pairs that we got from above meshGrid\n",
    "    CostFun=[]\n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            theta=[]\n",
    "            theta.append(theta_0[i,j])\n",
    "            theta.append(theta_1[i,j])\n",
    "            CostFun.append(costFuction(y,X,theta))\n",
    "\n",
    "    CostFun= np.reshape(CostFun,theta_0.shape)\n",
    "    ax.plot_surface(theta_0,theta_1,CostFun,alpha = 1,cmap = cm.GnBu)\n",
    "    ax.set_xlabel('theta_0')\n",
    "    ax.set_ylabel('theta_1')\n",
    "    ax.set_zlabel('Jtheta')\n",
    "    \n",
    "    #initializs the line for 3d animation\n",
    "    lines, = ax.plot([], [],[],color = 'green',markersize = 2)\n",
    "    def animationLine(i):\n",
    "            lines.set_data(thetaList0[:i],thetaList1[:i])\n",
    "            lines.set_3d_properties(costPlot[:i])\n",
    "            lines.set_marker(\"x\")\n",
    "            return lines,\n",
    "\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animationLine,frames=len(thetaList0),interval=200, repeat = True)\n",
    "\n",
    "    plt.show(block = False)\n",
    "    return anim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countourPLot(x,y,X,theta,costPlot,thetaList0,thetaList1):\n",
    "    #contour plot \n",
    "#     (x,y,X) = align()\n",
    "#     ( x,y,X,theta,costPlot,thetaList0,thetaList1) = gradientDescent(x,y,X)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "  #create 100 different theta values for plotting plot_surface\n",
    "    th0 = np.linspace(theta[0:1,:]-1,theta[0:1,:]+1,100)\n",
    "    th1 = np.linspace(theta[1:2,:]-1,theta[1:2,:]+1,100)\n",
    "\n",
    "#     (x,y,X) = align()\n",
    "    # meshGrid to create all possible pairs od theta in X and Y axis\n",
    "    theta_0,theta_1 = np.meshgrid(th0,th1)\n",
    "\n",
    "    CostFun=[]\n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            theta=[]\n",
    "            theta.append(theta_0[i,j])\n",
    "            theta.append(theta_1[i,j])\n",
    "            CostFun.append(costFuction(y,X,theta))\n",
    "\n",
    "    CostFun= np.reshape(CostFun,theta_0.shape)\n",
    "    CS = ax.contour(theta_0,theta_1,CostFun,alpha = 1)\n",
    "    ax.clabel(CS, inline=1, fontsize=10)\n",
    "\n",
    "    lines, = ax.plot([], [],color = 'green',markersize = 2)\n",
    "    def animationLine(i):\n",
    "            lines.set_data(thetaList0[:i],thetaList1[:i])\n",
    "            lines.set_marker(\"x\")\n",
    "            return lines,\n",
    "\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animationLine,frames=len(thetaList0),interval=200, repeat = False)\n",
    "\n",
    "    plt.show()\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countourPLot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    startTime = time()\n",
    "    #taking input and converting it into apropriate formats to be used further\n",
    "    (x,y,X) = align()\n",
    "    \n",
    "    #calculate gradient descent for linear regression\n",
    "    (x,y,X,theta,costPlot,thetaList0,thetaList1) = gradientDescent(x,y,X)\n",
    "    \n",
    "    # plot 2D graph and learned hypothesis\n",
    "    hypo = plot(x,y,X,theta,costPlot,thetaList0,thetaList1)\n",
    "   \n",
    "    \n",
    "    # plot surface_plot of the cost function and animate the hypothesis\n",
    "    anim1 = surface_plot(x,y,X,theta,costPlot,thetaList0,thetaList1)\n",
    "    \n",
    "    # plot countour and animate the hypothesis\n",
    "    anim2 = countourPLot(x,y,X,theta,costPlot,thetaList0,thetaList1)\n",
    "    endTime = time() - startTime\n",
    "    print(endTime)\n",
    "    return hypo,anim1,anim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8216338157653809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.lines.Line2D at 0x7f4e03958f28>,\n",
       " <matplotlib.animation.FuncAnimation at 0x7f4e1012d7f0>,\n",
       " <matplotlib.animation.FuncAnimation at 0x7f4e080dfac8>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
